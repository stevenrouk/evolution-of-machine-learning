{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NOTEBOOKS_DIR = os.path.abspath(os.getcwd())\n",
    "ROOT_DIR = os.path.split(NOTEBOOKS_DIR)[0]\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "\n",
    "FINAL_DF_FILEPATH = os.path.join(PROCESSED_DATA_DIR, 'final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(FINAL_DF_FILEPATH, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "math                70513\n",
       "physics:astro-ph    52289\n",
       "physics:cond-mat    48181\n",
       "cs                  23133\n",
       "physics:hep-ph      15842\n",
       "physics:physics     15812\n",
       "physics:quant-ph    10235\n",
       "physics:hep-th       8575\n",
       "physics:gr-qc        8251\n",
       "physics:hep-ex       6504\n",
       "physics:nucl-th      3312\n",
       "physics:hep-lat      3049\n",
       "nlin                 2607\n",
       "physics:nucl-ex      2309\n",
       "q-bio                2120\n",
       "stat                 1670\n",
       "physics:nlin          883\n",
       "q-fin                 688\n",
       "econ                   16\n",
       "Name: set_spec, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['set_spec'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs = df[df['set_spec'] == 'cs']\n",
    "df_math = df[df['set_spec'] == 'math']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>set_spec</th>\n",
       "      <th>subjects</th>\n",
       "      <th>authors</th>\n",
       "      <th>dates</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>oai:arXiv.org:1011.5311</td>\n",
       "      <td>http://arxiv.org/abs/1011.5311</td>\n",
       "      <td>Citations and impact of Dutch astronomy</td>\n",
       "      <td>cs</td>\n",
       "      <td>Astrophysics - Instrumentation and Methods for...</td>\n",
       "      <td>Kamphuis, P.,van der Kruit, P. C.</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>The aim of this study is to make a bibliomet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>oai:arXiv.org:1011.5314</td>\n",
       "      <td>http://arxiv.org/abs/1011.5314</td>\n",
       "      <td>ML(n)BiCGStab: Reformulation, Analysis and Imp...</td>\n",
       "      <td>cs</td>\n",
       "      <td>Mathematics - Numerical Analysis,Computer Scie...</td>\n",
       "      <td>Yeung, Man-Chung</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>With the aid of index functions, we re-deriv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>oai:arXiv.org:1011.5317</td>\n",
       "      <td>http://arxiv.org/abs/1011.5317</td>\n",
       "      <td>Performance of CSMA in Multi-Channel Wireless ...</td>\n",
       "      <td>cs</td>\n",
       "      <td>Computer Science - Networking and Internet Arc...</td>\n",
       "      <td>Bonald, Thomas,Feuillet, Mathieu</td>\n",
       "      <td>2010-11-24,2011-04-02</td>\n",
       "      <td>We analyze the performance of CSMA in multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>oai:arXiv.org:1011.5320</td>\n",
       "      <td>http://arxiv.org/abs/1011.5320</td>\n",
       "      <td>Computation of the shortest path between two c...</td>\n",
       "      <td>cs</td>\n",
       "      <td>Computer Science - Computational Geometry,Math...</td>\n",
       "      <td>Chen, Wen-Haw,Chen, Sheng-Gwo</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>In this paper, we present the geodesic-like ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>oai:arXiv.org:1011.5325</td>\n",
       "      <td>http://arxiv.org/abs/1011.5325</td>\n",
       "      <td>World of Movable Objects. Part 2</td>\n",
       "      <td>cs</td>\n",
       "      <td>Computer Science - Human-Computer Interaction</td>\n",
       "      <td>Andreyev, Sergey</td>\n",
       "      <td>2010-11-24</td>\n",
       "      <td>This book is about the transformation of scr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 identifier                             url  \\\n",
       "10  oai:arXiv.org:1011.5311  http://arxiv.org/abs/1011.5311   \n",
       "13  oai:arXiv.org:1011.5314  http://arxiv.org/abs/1011.5314   \n",
       "16  oai:arXiv.org:1011.5317  http://arxiv.org/abs/1011.5317   \n",
       "19  oai:arXiv.org:1011.5320  http://arxiv.org/abs/1011.5320   \n",
       "24  oai:arXiv.org:1011.5325  http://arxiv.org/abs/1011.5325   \n",
       "\n",
       "                                                title set_spec  \\\n",
       "10            Citations and impact of Dutch astronomy       cs   \n",
       "13  ML(n)BiCGStab: Reformulation, Analysis and Imp...       cs   \n",
       "16  Performance of CSMA in Multi-Channel Wireless ...       cs   \n",
       "19  Computation of the shortest path between two c...       cs   \n",
       "24                   World of Movable Objects. Part 2       cs   \n",
       "\n",
       "                                             subjects  \\\n",
       "10  Astrophysics - Instrumentation and Methods for...   \n",
       "13  Mathematics - Numerical Analysis,Computer Scie...   \n",
       "16  Computer Science - Networking and Internet Arc...   \n",
       "19  Computer Science - Computational Geometry,Math...   \n",
       "24      Computer Science - Human-Computer Interaction   \n",
       "\n",
       "                              authors                  dates  \\\n",
       "10  Kamphuis, P.,van der Kruit, P. C.             2010-11-24   \n",
       "13                   Yeung, Man-Chung             2010-11-24   \n",
       "16   Bonald, Thomas,Feuillet, Mathieu  2010-11-24,2011-04-02   \n",
       "19      Chen, Wen-Haw,Chen, Sheng-Gwo             2010-11-24   \n",
       "24                   Andreyev, Sergey             2010-11-24   \n",
       "\n",
       "                                          description  \n",
       "10    The aim of this study is to make a bibliomet...  \n",
       "13    With the aid of index functions, we re-deriv...  \n",
       "16    We analyze the performance of CSMA in multi-...  \n",
       "19    In this paper, we present the geodesic-like ...  \n",
       "24    This book is about the transformation of scr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10, 21}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_cs['dates'].map(len).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     16048\n",
       "False     7085\n",
       "Name: dates, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most of our data only has one data, but quite a bit has two dates.\n",
    "(df_cs['dates'].map(len) == 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs_dates = df_cs[df_cs['dates'].map(len) == 10]['dates'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(df_cs_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(c.keys())\n",
    "y = [c[i] for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-03-31\n",
      "2011-07-20\n"
     ]
    }
   ],
   "source": [
    "print(min(x))\n",
    "print(max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = df_cs['description'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16915"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  In this paper I present several novel, efficient, algorithmic techniques for\\nsolving some multidimensional geometric data management and analysis problems.\\nThe techniques are based on several data structures from computational geometry\\n(e.g. segment tree and range tree) and on the well-known sweep-line method.\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  In this paper we present a simple and robust method for self-correction of\\ncamera distortion using single images of scenes which contain straight lines.\\nSince the most common distortion can be modelled as radial distortion, we\\nillustrate the method using the Harris radial distortion model, but the method\\nis applicable to any distortion model. The method is based on transforming the\\nedgels of the distorted image to a 1-D angular Hough space, and optimizing the\\ndistortion correction parameters which minimize the entropy of the\\ncorresponding normalized histogram. Properly corrected imagery will have fewer\\ncurved lines, and therefore less spread in Hough space. Since the method does\\nnot rely on any image structure beyond the existence of edgels sharing some\\ncommon orientations and does not use edge fitting, it is applicable to a wide\\nvariety of image types. For instance, it can be applied equally well to images\\nof texture with weak but dominant orientations, or images with strong vanishing\\npoints. Finally, the method is performed on both synthetic and real data\\nrevealing that it is particularly robust to noise.\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Graphs are typically visualized as node-link diagrams. Although there is a\\nfair amount of research focusing on crossing minimization to improve\\nreadability, little attention has been paid on how to handle crossings when\\nthey are an essential part of the final visualizations. This requires us to\\nunderstand how people read graphs and how crossings affect reading performance.\\n  As an initial step to this end, a preliminary eye tracking experiment was\\nconducted. The specific purpose of this experiment was to test the effects of\\ncrossing angles and geometric-path tendency on eye movements and performance.\\nSixteen subjects performed both path search and node locating tasks with six\\ndrawings. The results showed that small angles can slow down and trigger extra\\neye movements, causing delays for path search tasks, whereas crossings have\\nlittle impact on node locating tasks. Geometric-path tendency indicates that a\\npath between two nodes can become harder to follow when many branches of the\\npath go toward the target node. The insights obtained are discussed with a view\\nto further confirmation in future work.\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = vectorizer.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0001',\n",
       " '0001071',\n",
       " '0004609',\n",
       " '000s',\n",
       " '0025',\n",
       " '005',\n",
       " '00509488',\n",
       " '0071v4',\n",
       " '0084',\n",
       " '01',\n",
       " '010',\n",
       " '01020103',\n",
       " '0103200',\n",
       " '010401',\n",
       " '013',\n",
       " '015',\n",
       " '0167',\n",
       " '017',\n",
       " '0170',\n",
       " '02',\n",
       " '0207023',\n",
       " '024',\n",
       " '025',\n",
       " '029',\n",
       " '03',\n",
       " '0307',\n",
       " '031',\n",
       " '0310049',\n",
       " '035n',\n",
       " '036111',\n",
       " '0367',\n",
       " '04',\n",
       " '040',\n",
       " '0410',\n",
       " '0410460v2',\n",
       " '0412187',\n",
       " '0423',\n",
       " '046',\n",
       " '0463',\n",
       " '0476',\n",
       " '04db',\n",
       " '05',\n",
       " '0501076',\n",
       " '0501315',\n",
       " '0506134',\n",
       " '0511096',\n",
       " '0595',\n",
       " '05a',\n",
       " '05kw',\n",
       " '06',\n",
       " '0602345',\n",
       " '0604',\n",
       " '0604017',\n",
       " '0605181',\n",
       " '0609101',\n",
       " '0609825v5',\n",
       " '0612509v2',\n",
       " '062',\n",
       " '0625',\n",
       " '0665',\n",
       " '068',\n",
       " '069',\n",
       " '07',\n",
       " '0701020v2',\n",
       " '0701096v2',\n",
       " '0703125',\n",
       " '0708',\n",
       " '0709',\n",
       " '0710',\n",
       " '0711',\n",
       " '073',\n",
       " '0746',\n",
       " '076',\n",
       " '0783',\n",
       " '079',\n",
       " '07cc',\n",
       " '08',\n",
       " '0801',\n",
       " '0802',\n",
       " '0803',\n",
       " '0805',\n",
       " '0807',\n",
       " '0809',\n",
       " '081',\n",
       " '0810',\n",
       " '0811',\n",
       " '0812',\n",
       " '083',\n",
       " '085',\n",
       " '0854',\n",
       " '088',\n",
       " '0883',\n",
       " '08bss',\n",
       " '09',\n",
       " '0901',\n",
       " '0902',\n",
       " '0903',\n",
       " '0905',\n",
       " '0907',\n",
       " '0908',\n",
       " '0910',\n",
       " '0912',\n",
       " '0919',\n",
       " '0977',\n",
       " '0_',\n",
       " '0_1',\n",
       " '0_2',\n",
       " '0_3',\n",
       " '0_3u',\n",
       " '0_4',\n",
       " '0_alpha',\n",
       " '0_n',\n",
       " '0_omega',\n",
       " '0db',\n",
       " '0e6c1294',\n",
       " '0f4d28b1',\n",
       " '0fcffaa1',\n",
       " '0s',\n",
       " '0th',\n",
       " '0v',\n",
       " '0w',\n",
       " '0xley',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '1001',\n",
       " '1002',\n",
       " '1003',\n",
       " '1004',\n",
       " '1005',\n",
       " '1007',\n",
       " '1008',\n",
       " '1009',\n",
       " '100bp',\n",
       " '100gflop',\n",
       " '100ms',\n",
       " '100nm',\n",
       " '100s',\n",
       " '100x',\n",
       " '100x100',\n",
       " '101',\n",
       " '1012',\n",
       " '1016',\n",
       " '10168',\n",
       " '102',\n",
       " '1022',\n",
       " '1024',\n",
       " '1024x768',\n",
       " '1026',\n",
       " '103',\n",
       " '104',\n",
       " '1044',\n",
       " '1045',\n",
       " '105',\n",
       " '1050',\n",
       " '1055',\n",
       " '106',\n",
       " '1060',\n",
       " '107',\n",
       " '1070',\n",
       " '10791',\n",
       " '108',\n",
       " '1083',\n",
       " '1088',\n",
       " '109',\n",
       " '1099',\n",
       " '10db',\n",
       " '10gb',\n",
       " '10k',\n",
       " '10kpa',\n",
       " '10mag',\n",
       " '10mhz',\n",
       " '10n',\n",
       " '10th',\n",
       " '10w',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '1101',\n",
       " '1105',\n",
       " '1107',\n",
       " '110ms',\n",
       " '111',\n",
       " '1113',\n",
       " '112',\n",
       " '11213',\n",
       " '113',\n",
       " '1133',\n",
       " '114',\n",
       " '1148',\n",
       " '1149',\n",
       " '115',\n",
       " '1150',\n",
       " '116',\n",
       " '1162',\n",
       " '117',\n",
       " '117821',\n",
       " '118',\n",
       " '1185',\n",
       " '1186',\n",
       " '119',\n",
       " '1193',\n",
       " '11a',\n",
       " '11b',\n",
       " '11e',\n",
       " '11g',\n",
       " '11k',\n",
       " '11n',\n",
       " '11s',\n",
       " '11standard',\n",
       " '11th',\n",
       " '11x',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '12020598',\n",
       " '1204',\n",
       " '1209',\n",
       " '120n',\n",
       " '121',\n",
       " '1210',\n",
       " '1213wh',\n",
       " '122',\n",
       " '1226',\n",
       " '123',\n",
       " '1232',\n",
       " '1235',\n",
       " '124',\n",
       " '12446',\n",
       " '12450',\n",
       " '125',\n",
       " '1251',\n",
       " '126',\n",
       " '127',\n",
       " '1279',\n",
       " '128',\n",
       " '128000',\n",
       " '128bits',\n",
       " '128ks',\n",
       " '129',\n",
       " '12bit',\n",
       " '12db',\n",
       " '12f',\n",
       " '12l',\n",
       " '12mm',\n",
       " '12n',\n",
       " '12th',\n",
       " '12x',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '13000',\n",
       " '130khz',\n",
       " '132',\n",
       " '13211',\n",
       " '1325',\n",
       " '1341',\n",
       " '1348',\n",
       " '135',\n",
       " '1350',\n",
       " '1354',\n",
       " '136',\n",
       " '1364',\n",
       " '137',\n",
       " '138',\n",
       " '1383wh',\n",
       " '139',\n",
       " '13db',\n",
       " '13m',\n",
       " '13th',\n",
       " '13x',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '140000',\n",
       " '1406',\n",
       " '140ms',\n",
       " '141',\n",
       " '14116',\n",
       " '144',\n",
       " '1468',\n",
       " '147',\n",
       " '148',\n",
       " '148701',\n",
       " '149',\n",
       " '14db',\n",
       " '14kpa',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1504',\n",
       " '150m',\n",
       " '150mbps',\n",
       " '150mm',\n",
       " '150mmx',\n",
       " '151',\n",
       " '1520',\n",
       " '1527',\n",
       " '153',\n",
       " '1535',\n",
       " '154',\n",
       " '15408',\n",
       " '1545',\n",
       " '15450',\n",
       " '155',\n",
       " '1555v1',\n",
       " '155mbps',\n",
       " '156',\n",
       " '157',\n",
       " '1571',\n",
       " '158',\n",
       " '15855',\n",
       " '159',\n",
       " '15mm',\n",
       " '15mv',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '160k',\n",
       " '160mw',\n",
       " '161',\n",
       " '162',\n",
       " '163',\n",
       " '16384',\n",
       " '164',\n",
       " '165',\n",
       " '1652',\n",
       " '1656',\n",
       " '1666',\n",
       " '167',\n",
       " '16e',\n",
       " '16m',\n",
       " '16n',\n",
       " '16qam',\n",
       " '16s',\n",
       " '16sqr',\n",
       " '16th',\n",
       " '16x',\n",
       " '16x16',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '171',\n",
       " '1712',\n",
       " '1713',\n",
       " '1723',\n",
       " '1728',\n",
       " '1737',\n",
       " '1742',\n",
       " '1743',\n",
       " '175',\n",
       " '1750',\n",
       " '176',\n",
       " '17780x3204',\n",
       " '17799',\n",
       " '178',\n",
       " '1780',\n",
       " '179',\n",
       " '1790',\n",
       " '1794',\n",
       " '17n',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '1809',\n",
       " '181',\n",
       " '1810',\n",
       " '1814',\n",
       " '182',\n",
       " '1826',\n",
       " '1829',\n",
       " '183',\n",
       " '1832',\n",
       " '184',\n",
       " '1844',\n",
       " '1852',\n",
       " '186',\n",
       " '1864',\n",
       " '1868',\n",
       " '1879',\n",
       " '188',\n",
       " '1880',\n",
       " '1881',\n",
       " '1883',\n",
       " '1886',\n",
       " '1889',\n",
       " '189',\n",
       " '1891',\n",
       " '1892m',\n",
       " '1893',\n",
       " '1894',\n",
       " '18p',\n",
       " '18th',\n",
       " '18x18',\n",
       " '19',\n",
       " '1900',\n",
       " '19005',\n",
       " '1901',\n",
       " '1905',\n",
       " '1908',\n",
       " '19115',\n",
       " '19137',\n",
       " '1916',\n",
       " '192',\n",
       " '1920',\n",
       " '1923',\n",
       " '1927',\n",
       " '1928',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1931',\n",
       " '1934',\n",
       " '1936',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1942',\n",
       " '1945',\n",
       " '1946',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '195',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1952',\n",
       " '1953',\n",
       " '1955',\n",
       " '1956',\n",
       " '1957',\n",
       " '1958',\n",
       " '1959',\n",
       " '196',\n",
       " '1960',\n",
       " '1960ies',\n",
       " '1960s',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '196608',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '197',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1998a',\n",
       " '1998b',\n",
       " '1999',\n",
       " '19c',\n",
       " '19th',\n",
       " '1_',\n",
       " '1_1',\n",
       " '1_2',\n",
       " '1_p',\n",
       " '1a1',\n",
       " '1aa',\n",
       " '1bendpointsetembeddability',\n",
       " '1bit',\n",
       " '1cm2',\n",
       " '1cognitive',\n",
       " '1d',\n",
       " '1db',\n",
       " '1deg',\n",
       " '1e',\n",
       " '1hp',\n",
       " '1j',\n",
       " '1m',\n",
       " '1microa',\n",
       " '1mm3',\n",
       " '1n',\n",
       " '1nf',\n",
       " '1pc',\n",
       " '1pfa',\n",
       " '1pm6',\n",
       " '1qfa',\n",
       " '1qfac',\n",
       " '1rsb',\n",
       " '1s',\n",
       " '1st',\n",
       " '1th',\n",
       " '1v',\n",
       " '1w',\n",
       " '1xrtt',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '20008',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2004b',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2009a',\n",
       " '2009b',\n",
       " '200ms',\n",
       " '200um',\n",
       " '200x',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2016',\n",
       " '2023',\n",
       " '2024',\n",
       " '2030',\n",
       " '204',\n",
       " '2047',\n",
       " '2048',\n",
       " '20484',\n",
       " '205',\n",
       " '2058',\n",
       " '206',\n",
       " '2061',\n",
       " '207',\n",
       " '208',\n",
       " '209',\n",
       " '20k',\n",
       " '20m',\n",
       " '20n',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '210',\n",
       " '211',\n",
       " '2113',\n",
       " '211m',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '2149',\n",
       " '215',\n",
       " '2156',\n",
       " '21578',\n",
       " '2158',\n",
       " '215x215',\n",
       " '216',\n",
       " '2165',\n",
       " '2167',\n",
       " '217',\n",
       " '2172',\n",
       " '218',\n",
       " '21ghz',\n",
       " '21st',\n",
       " '21th',\n",
       " '22',\n",
       " '220',\n",
       " '220khz',\n",
       " '221',\n",
       " '2210',\n",
       " '223',\n",
       " '224',\n",
       " '226',\n",
       " '227',\n",
       " '2270',\n",
       " '228',\n",
       " '2291',\n",
       " '22d',\n",
       " '22nd',\n",
       " '23',\n",
       " '230',\n",
       " '2312388',\n",
       " '232',\n",
       " '233',\n",
       " '2338',\n",
       " '2340',\n",
       " '2342',\n",
       " '235',\n",
       " '2351734',\n",
       " '2355',\n",
       " '236',\n",
       " '237',\n",
       " '2386v4',\n",
       " '239',\n",
       " '2396',\n",
       " '23sqrt',\n",
       " '23th',\n",
       " '24',\n",
       " '240',\n",
       " '24036583',\n",
       " '241',\n",
       " '242',\n",
       " '245',\n",
       " '2462',\n",
       " '247',\n",
       " '24731',\n",
       " '249',\n",
       " '24ghz',\n",
       " '24th',\n",
       " '24v',\n",
       " '24x24',\n",
       " '24x9',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '25000',\n",
       " '250x30x15',\n",
       " '251',\n",
       " '252',\n",
       " '252nd',\n",
       " '254',\n",
       " '255',\n",
       " '256',\n",
       " '2567',\n",
       " '256bit',\n",
       " '256bits',\n",
       " '258',\n",
       " '2584',\n",
       " '2585',\n",
       " '2589',\n",
       " '259',\n",
       " '2593',\n",
       " '25mm',\n",
       " '25n',\n",
       " '25nm',\n",
       " '25ps',\n",
       " '25th',\n",
       " '25x18',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2602',\n",
       " '261',\n",
       " '264',\n",
       " '2659',\n",
       " '267',\n",
       " '2688',\n",
       " '26th',\n",
       " '27',\n",
       " '270',\n",
       " '27001',\n",
       " '2703v1',\n",
       " '2732',\n",
       " '274',\n",
       " '275',\n",
       " '276',\n",
       " '2769',\n",
       " '277',\n",
       " '278',\n",
       " '2782',\n",
       " '278uwcm',\n",
       " '279',\n",
       " '2791',\n",
       " '279917',\n",
       " '28',\n",
       " '280',\n",
       " '2800',\n",
       " '28000',\n",
       " '287',\n",
       " '288',\n",
       " '289',\n",
       " '28th',\n",
       " '29',\n",
       " '290',\n",
       " '291',\n",
       " '292',\n",
       " '296',\n",
       " '297',\n",
       " '2975',\n",
       " '299',\n",
       " '29m',\n",
       " '29th',\n",
       " '2a',\n",
       " '2alpha',\n",
       " '2b',\n",
       " '2bench',\n",
       " '2bit',\n",
       " '2c',\n",
       " '2c_4',\n",
       " '2d',\n",
       " '2db',\n",
       " '2dbda',\n",
       " '2ddwt',\n",
       " '2delta',\n",
       " '2dhlda',\n",
       " '2dlda',\n",
       " '2dmbc',\n",
       " '2dpca',\n",
       " '2drank',\n",
       " '2dw',\n",
       " '2dxtime',\n",
       " '2e',\n",
       " '2ec',\n",
       " '2expspace',\n",
       " '2exptime',\n",
       " '2f',\n",
       " '2f_',\n",
       " '2g',\n",
       " '2gapts',\n",
       " '2gbps',\n",
       " '2gsps',\n",
       " '2h',\n",
       " '2h6',\n",
       " '2hp',\n",
       " '2i',\n",
       " '2j',\n",
       " '2k',\n",
       " '2l',\n",
       " '2log',\n",
       " '2m',\n",
       " '2mag',\n",
       " '2mn',\n",
       " '2n',\n",
       " '2n_f',\n",
       " '2nd',\n",
       " '2nfa',\n",
       " '2nlogn',\n",
       " '2nmatrices',\n",
       " '2nmatrix',\n",
       " '2np',\n",
       " '2p',\n",
       " '2pfa',\n",
       " '2pm',\n",
       " '2ppls',\n",
       " '2q',\n",
       " '2qfa',\n",
       " '2r',\n",
       " '2rc',\n",
       " '2s',\n",
       " '2sat',\n",
       " '2snr',\n",
       " '2sqrt',\n",
       " '2t',\n",
       " '2v',\n",
       " '2v_',\n",
       " '2vc',\n",
       " '2w',\n",
       " '2w_',\n",
       " '2x',\n",
       " '2x1',\n",
       " '2x2',\n",
       " '2x2bit',\n",
       " '2xn',\n",
       " '2y',\n",
       " '2z',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300m',\n",
       " '300x',\n",
       " '3029',\n",
       " '3033',\n",
       " '304',\n",
       " '305',\n",
       " '307',\n",
       " '308',\n",
       " '309',\n",
       " '30at',\n",
       " '30db',\n",
       " '30f',\n",
       " '30k',\n",
       " '30th',\n",
       " '31',\n",
       " '3104v1',\n",
       " '312',\n",
       " '3120',\n",
       " '314',\n",
       " '3142',\n",
       " '3159',\n",
       " '3166',\n",
       " '317',\n",
       " '3173',\n",
       " '3183',\n",
       " '31st',\n",
       " '31th',\n",
       " '32',\n",
       " '320',\n",
       " '32065',\n",
       " '320c',\n",
       " '32113',\n",
       " '32153',\n",
       " '32216',\n",
       " '32258',\n",
       " '3228',\n",
       " '323',\n",
       " '3239',\n",
       " '3247',\n",
       " '325',\n",
       " '329',\n",
       " '32k',\n",
       " '32kb',\n",
       " '32x',\n",
       " '32x32',\n",
       " '33',\n",
       " '330',\n",
       " '3308',\n",
       " '3314',\n",
       " '332',\n",
       " '333',\n",
       " '3333',\n",
       " '334',\n",
       " '336',\n",
       " '34',\n",
       " '340',\n",
       " '3404v4',\n",
       " '341',\n",
       " '3448',\n",
       " '345',\n",
       " '3466',\n",
       " '3473',\n",
       " '34kbits',\n",
       " '34x',\n",
       " '35',\n",
       " '351',\n",
       " '352',\n",
       " '3529',\n",
       " '353',\n",
       " '3540',\n",
       " '3544',\n",
       " '3545',\n",
       " '356',\n",
       " '3569',\n",
       " '357',\n",
       " '3570',\n",
       " '358',\n",
       " '3580v2',\n",
       " '359',\n",
       " '3590',\n",
       " '3593',\n",
       " '36',\n",
       " '360',\n",
       " '361',\n",
       " '3623',\n",
       " '3624',\n",
       " '363',\n",
       " '3631',\n",
       " '365',\n",
       " '367',\n",
       " '3679',\n",
       " '37',\n",
       " '3721',\n",
       " '373',\n",
       " '375',\n",
       " '3757',\n",
       " '376',\n",
       " '3763v1',\n",
       " '377',\n",
       " '379',\n",
       " '37mm',\n",
       " '38',\n",
       " '3804',\n",
       " '3824v4',\n",
       " '383',\n",
       " '3833',\n",
       " '384',\n",
       " '38408',\n",
       " '386',\n",
       " '387',\n",
       " '388',\n",
       " '39',\n",
       " '390',\n",
       " '391',\n",
       " '392',\n",
       " '393',\n",
       " '394',\n",
       " '3963v1',\n",
       " '399',\n",
       " '3999',\n",
       " '3a',\n",
       " '3an',\n",
       " '3apl',\n",
       " '3as',\n",
       " '3c',\n",
       " '3cnf',\n",
       " '3com',\n",
       " '3d',\n",
       " '3db',\n",
       " '3des',\n",
       " '3dskull',\n",
       " '3e',\n",
       " '3f',\n",
       " '3g',\n",
       " '3gpp',\n",
       " '3gpp2',\n",
       " '3i',\n",
       " '3k',\n",
       " '3l',\n",
       " '3m',\n",
       " '3micron',\n",
       " '3mm',\n",
       " '3mw',\n",
       " '3n',\n",
       " '3n_t',\n",
       " '3p',\n",
       " '3qbf',\n",
       " '3r',\n",
       " '3rc',\n",
       " '3rd',\n",
       " '3s',\n",
       " '3sat',\n",
       " '3sn',\n",
       " '3sn2',\n",
       " '3sum',\n",
       " '3t',\n",
       " '3tb',\n",
       " '3v3',\n",
       " '3x',\n",
       " '3x3',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40000',\n",
       " '400ff',\n",
       " '402',\n",
       " '4026265b',\n",
       " '404',\n",
       " '405',\n",
       " '406',\n",
       " '407',\n",
       " '4095',\n",
       " '4096',\n",
       " '40k',\n",
       " '40msec',\n",
       " '40n',\n",
       " '41',\n",
       " '410',\n",
       " '410256',\n",
       " '413',\n",
       " '413793',\n",
       " '414',\n",
       " '4142m',\n",
       " '4143',\n",
       " '4176',\n",
       " '419',\n",
       " '41mm',\n",
       " '42',\n",
       " '420',\n",
       " '422',\n",
       " '424n',\n",
       " '425',\n",
       " '4262',\n",
       " '427',\n",
       " '4273',\n",
       " '428',\n",
       " '429',\n",
       " '4293',\n",
       " '4294',\n",
       " '43',\n",
       " '4307',\n",
       " '430nm',\n",
       " '431',\n",
       " '433',\n",
       " '4338',\n",
       " '434',\n",
       " '4354',\n",
       " '437',\n",
       " '438',\n",
       " '439',\n",
       " '44',\n",
       " '440',\n",
       " '441n',\n",
       " '4423',\n",
       " '4427',\n",
       " '443',\n",
       " '444',\n",
       " '445',\n",
       " ...]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_vectorizer.fit_transform(descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00506781 0.00607851 0.00492608 0.0036822  0.0034717  0.00300686\n",
      " 0.00284712 0.00245702 0.00235219 0.00219536]\n",
      "0.03608484518816286\n",
      "[33.07165716  9.8596289   8.85028021  7.65733894  7.44016161  6.93299996\n",
      "  6.7283403   6.25975719  6.11560688  5.90884147]\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=10, n_iter=7, random_state=42)\n",
    "svd.fit(tfidf)\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "U, Sigma, VT = randomized_svd(tfidf, \n",
    "                              n_components=10,\n",
    "                              n_iter=7,\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.07165716,  9.8596289 ,  8.85028021,  7.65733894,  7.44016161,\n",
       "        6.93299996,  6.7283403 ,  6.25975719,  6.11560688,  5.90884147])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 38246)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16915, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comp Sci - Word counts, n-gram counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "import string\n",
    "#from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def tokenize(sentence):\n",
    "    s = sentence.lower()\n",
    "    #tokens = nltk.word_tokenize(s)\n",
    "    translation = str.maketrans('', '', string.punctuation)\n",
    "    s = s.translate(translation)\n",
    "    tokens = s.split()\n",
    "    #punctuation_set = set(string.punctuation)\n",
    "    #tokens_no_punc = [t for t in tokens if t not in punctuation_set]\n",
    "    #wordnet = WordNetLemmatizer()\n",
    "    #lemmatized = [wordnet.lemmatize(word) for word in tokens_no_punc]\n",
    "\n",
    "    #return lemmatized\n",
    "    #return tokens_no_punc\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_tokenized = [tokenize(s) for s in descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'aim',\n",
       " 'of',\n",
       " 'this',\n",
       " 'study',\n",
       " 'is',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'bibliometric',\n",
       " 'comparison',\n",
       " 'of',\n",
       " 'the',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'research',\n",
       " 'astronomers',\n",
       " 'in',\n",
       " 'the',\n",
       " 'netherlands',\n",
       " 'research',\n",
       " 'school',\n",
       " 'for',\n",
       " 'astronomy',\n",
       " 'nova',\n",
       " 'with',\n",
       " 'astronomers',\n",
       " 'elsewhere',\n",
       " 'by',\n",
       " 'using',\n",
       " 'the',\n",
       " 'nasa',\n",
       " 'astrophysics',\n",
       " 'data',\n",
       " 'system',\n",
       " 'ads',\n",
       " 'we',\n",
       " 'use',\n",
       " 'various',\n",
       " 'indices',\n",
       " 'for',\n",
       " 'bibliometric',\n",
       " 'performance',\n",
       " 'for',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'of',\n",
       " 'nova',\n",
       " 'astronomers',\n",
       " 'to',\n",
       " 'compare',\n",
       " 'to',\n",
       " 'samples',\n",
       " 'of',\n",
       " 'astronomers',\n",
       " 'worldwide',\n",
       " 'and',\n",
       " 'from',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'we',\n",
       " 'give',\n",
       " 'much',\n",
       " 'weight',\n",
       " 'to',\n",
       " 'normalising',\n",
       " 'bibliometric',\n",
       " 'measures',\n",
       " 'by',\n",
       " 'number',\n",
       " 'of',\n",
       " 'authors',\n",
       " 'and',\n",
       " 'number',\n",
       " 'of',\n",
       " 'years',\n",
       " 'since',\n",
       " 'first',\n",
       " 'publication',\n",
       " 'in',\n",
       " 'particular',\n",
       " 'we',\n",
       " 'calculate',\n",
       " 'the',\n",
       " 'hirshindex',\n",
       " 'normalized',\n",
       " 'to',\n",
       " 'number',\n",
       " 'of',\n",
       " 'authors',\n",
       " 'and',\n",
       " 'for',\n",
       " 'firstauthor',\n",
       " 'papers',\n",
       " 'secondly',\n",
       " 'we',\n",
       " 'consider',\n",
       " 'the',\n",
       " 'results',\n",
       " 'of',\n",
       " 'the',\n",
       " 'nederlands',\n",
       " 'observatorium',\n",
       " 'van',\n",
       " 'wetenschap',\n",
       " 'en',\n",
       " 'technologie',\n",
       " 'nowt',\n",
       " 'netherlands',\n",
       " 'observatory',\n",
       " 'of',\n",
       " 'science',\n",
       " 'and',\n",
       " 'technology',\n",
       " 'which',\n",
       " 'regularly',\n",
       " 'publishes',\n",
       " 'a',\n",
       " 'report',\n",
       " 'science',\n",
       " 'and',\n",
       " 'technology',\n",
       " 'indicators',\n",
       " 'we',\n",
       " 'reproduce',\n",
       " 'those',\n",
       " 'results',\n",
       " 'using',\n",
       " 'publication',\n",
       " 'lists',\n",
       " 'from',\n",
       " 'institutions',\n",
       " 'in',\n",
       " 'the',\n",
       " 'netherlands',\n",
       " 'again',\n",
       " 'using',\n",
       " 'ads',\n",
       " 'and',\n",
       " 'examine',\n",
       " 'and',\n",
       " 'discuss',\n",
       " 'the',\n",
       " 'conclusions',\n",
       " 'and',\n",
       " 'indications',\n",
       " 'in',\n",
       " 'these',\n",
       " 'reports',\n",
       " 'we',\n",
       " 'find',\n",
       " 'that',\n",
       " 'the',\n",
       " 'nova',\n",
       " 'researchers',\n",
       " 'perform',\n",
       " 'much',\n",
       " 'better',\n",
       " 'in',\n",
       " 'bibliometric',\n",
       " 'measures',\n",
       " 'than',\n",
       " 'samples',\n",
       " 'drawn',\n",
       " 'from',\n",
       " 'iau',\n",
       " 'or',\n",
       " 'aas',\n",
       " 'membership',\n",
       " 'lists',\n",
       " 'a',\n",
       " 'more',\n",
       " 'suitable',\n",
       " 'comparison',\n",
       " 'is',\n",
       " 'one',\n",
       " 'with',\n",
       " 'the',\n",
       " 'tenured',\n",
       " 'staff',\n",
       " 'of',\n",
       " 'the',\n",
       " 'top15',\n",
       " 'us',\n",
       " 'institutions',\n",
       " 'and',\n",
       " 'there',\n",
       " 'the',\n",
       " 'nova',\n",
       " 'staff',\n",
       " 'performs',\n",
       " 'in',\n",
       " 'these',\n",
       " 'respects',\n",
       " 'as',\n",
       " 'good',\n",
       " 'or',\n",
       " 'almost',\n",
       " 'as',\n",
       " 'good',\n",
       " 'as',\n",
       " 'that',\n",
       " 'of',\n",
       " 'american',\n",
       " 'top',\n",
       " 'institutes',\n",
       " 'from',\n",
       " 'a',\n",
       " 'citation',\n",
       " 'analysis',\n",
       " 'through',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'ads',\n",
       " 'we',\n",
       " 'conclude',\n",
       " 'that',\n",
       " 'the',\n",
       " 'impact',\n",
       " 'ratio',\n",
       " 'of',\n",
       " 'dutch',\n",
       " 'astronomical',\n",
       " 'publications',\n",
       " 'is',\n",
       " 'rising',\n",
       " 'which',\n",
       " 'is',\n",
       " 'opposite',\n",
       " 'to',\n",
       " 'what',\n",
       " 'is',\n",
       " 'reported',\n",
       " 'by',\n",
       " 'nowt',\n",
       " 'this',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'most',\n",
       " 'likely',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'a',\n",
       " 'better',\n",
       " 'separation',\n",
       " 'of',\n",
       " 'astronomy',\n",
       " 'and',\n",
       " 'physics',\n",
       " 'in',\n",
       " 'ads',\n",
       " 'than',\n",
       " 'in',\n",
       " 'world',\n",
       " 'of',\n",
       " 'knowledge',\n",
       " 'ads',\n",
       " 'probably',\n",
       " 'finds',\n",
       " 'more',\n",
       " 'citations',\n",
       " 'in',\n",
       " 'conference',\n",
       " 'proceedings',\n",
       " 'while',\n",
       " 'the',\n",
       " 'inclusion',\n",
       " 'of',\n",
       " 'citations',\n",
       " 'to',\n",
       " 'articles',\n",
       " 'with',\n",
       " 'their',\n",
       " 'preprint',\n",
       " 'identifier',\n",
       " 'could',\n",
       " 'also',\n",
       " 'help',\n",
       " 'explain',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'especially',\n",
       " 'since',\n",
       " 'the',\n",
       " 'citation',\n",
       " 'windows',\n",
       " 'in',\n",
       " 'the',\n",
       " 'reports',\n",
       " 'are',\n",
       " 'short']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_cs = []\n",
    "vocab_cs = set()\n",
    "\n",
    "for sent in descriptions_tokenized:\n",
    "    for word in sent:\n",
    "        words_cs.append(word)\n",
    "        vocab_cs.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3195865"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72294"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Counter(words_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 210396),\n",
       " ('of', 135913),\n",
       " ('a', 89100),\n",
       " ('and', 82074),\n",
       " ('to', 70410),\n",
       " ('in', 68731),\n",
       " ('is', 56807),\n",
       " ('we', 47420),\n",
       " ('for', 45004),\n",
       " ('that', 38684),\n",
       " ('this', 31748),\n",
       " ('with', 25215),\n",
       " ('on', 25204),\n",
       " ('are', 24275),\n",
       " ('by', 20408),\n",
       " ('an', 20202),\n",
       " ('as', 20201),\n",
       " ('be', 16889),\n",
       " ('which', 14676),\n",
       " ('can', 13848),\n",
       " ('paper', 12433),\n",
       " ('it', 11950),\n",
       " ('problem', 10746),\n",
       " ('from', 10739),\n",
       " ('algorithm', 10358),\n",
       " ('our', 10120),\n",
       " ('show', 8738),\n",
       " ('data', 8356),\n",
       " ('at', 8224),\n",
       " ('network', 7863),\n",
       " ('such', 7740),\n",
       " ('results', 7646),\n",
       " ('also', 7629),\n",
       " ('model', 7537),\n",
       " ('or', 7467),\n",
       " ('based', 7459),\n",
       " ('has', 7368),\n",
       " ('using', 7355),\n",
       " ('these', 7222),\n",
       " ('time', 7079),\n",
       " ('number', 7021),\n",
       " ('system', 6998),\n",
       " ('information', 6939),\n",
       " ('have', 6926),\n",
       " ('two', 6660),\n",
       " ('not', 6276),\n",
       " ('new', 6100),\n",
       " ('one', 5972),\n",
       " ('proposed', 5701),\n",
       " ('channel', 5639),\n",
       " ('systems', 5609),\n",
       " ('networks', 5574),\n",
       " ('used', 5515),\n",
       " ('algorithms', 5510),\n",
       " ('between', 5441),\n",
       " ('where', 5435),\n",
       " ('its', 5381),\n",
       " ('all', 5224),\n",
       " ('set', 5167),\n",
       " ('each', 5101),\n",
       " ('performance', 5002),\n",
       " ('method', 4883),\n",
       " ('approach', 4813),\n",
       " ('their', 4806),\n",
       " ('when', 4727),\n",
       " ('some', 4680),\n",
       " ('present', 4665),\n",
       " ('been', 4601),\n",
       " ('over', 4442),\n",
       " ('more', 4438),\n",
       " ('different', 4300),\n",
       " ('analysis', 4253),\n",
       " ('problems', 4176),\n",
       " ('both', 4174),\n",
       " ('given', 4166),\n",
       " ('graph', 4154),\n",
       " ('use', 4133),\n",
       " ('study', 4123),\n",
       " ('only', 4042),\n",
       " ('first', 3990),\n",
       " ('any', 3975),\n",
       " ('than', 3972),\n",
       " ('case', 3917),\n",
       " ('n', 3887),\n",
       " ('other', 3871),\n",
       " ('optimal', 3830),\n",
       " ('if', 3780),\n",
       " ('complexity', 3777),\n",
       " ('codes', 3615),\n",
       " ('into', 3564),\n",
       " ('then', 3515),\n",
       " ('linear', 3462),\n",
       " ('but', 3429),\n",
       " ('work', 3390),\n",
       " ('rate', 3311),\n",
       " ('propose', 3295),\n",
       " ('bound', 3235),\n",
       " ('scheme', 3228),\n",
       " ('nodes', 3132),\n",
       " ('provide', 3127)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math descriptions and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_descriptions = df_math['description'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_descriptions_tokenized = [tokenize(s) for s in math_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_math = []\n",
    "vocab_math = set()\n",
    "\n",
    "for sent in math_descriptions_tokenized:\n",
    "    for word in sent:\n",
    "        words_math.append(word)\n",
    "        vocab_math.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6440380"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152388"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_math = Counter(words_math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 456964),\n",
       " ('of', 361459),\n",
       " ('a', 209841),\n",
       " ('and', 150926),\n",
       " ('in', 138187),\n",
       " ('we', 136198),\n",
       " ('is', 115536),\n",
       " ('to', 111747),\n",
       " ('for', 91751),\n",
       " ('that', 77353),\n",
       " ('this', 59302),\n",
       " ('on', 58318),\n",
       " ('with', 57407),\n",
       " ('are', 49687),\n",
       " ('by', 45323),\n",
       " ('an', 43544),\n",
       " ('as', 34350),\n",
       " ('which', 30412),\n",
       " ('be', 29601),\n",
       " ('show', 21267),\n",
       " ('paper', 20267),\n",
       " ('it', 19246),\n",
       " ('prove', 18691),\n",
       " ('also', 18240),\n",
       " ('from', 17461),\n",
       " ('these', 16804),\n",
       " ('space', 16510),\n",
       " ('results', 16374),\n",
       " ('group', 16219),\n",
       " ('some', 15865),\n",
       " ('if', 15647),\n",
       " ('can', 14501),\n",
       " ('such', 14456),\n",
       " ('study', 14405),\n",
       " ('two', 13909),\n",
       " ('theory', 13431),\n",
       " ('at', 13364),\n",
       " ('case', 13052),\n",
       " ('our', 13011),\n",
       " ('all', 12628),\n",
       " ('one', 12533),\n",
       " ('finite', 12338),\n",
       " ('or', 12149),\n",
       " ('has', 12080),\n",
       " ('function', 11883),\n",
       " ('give', 11460),\n",
       " ('number', 11196),\n",
       " ('result', 11126),\n",
       " ('problem', 11116),\n",
       " ('not', 11112),\n",
       " ('new', 11087),\n",
       " ('functions', 10933),\n",
       " ('where', 10805),\n",
       " ('given', 10801),\n",
       " ('over', 10796),\n",
       " ('then', 10751),\n",
       " ('g', 10733),\n",
       " ('n', 10599),\n",
       " ('algebra', 10530),\n",
       " ('set', 10406),\n",
       " ('its', 10374),\n",
       " ('equation', 10267),\n",
       " ('model', 10109),\n",
       " ('equations', 9818),\n",
       " ('class', 9681),\n",
       " ('any', 9631),\n",
       " ('x', 9461),\n",
       " ('using', 9266),\n",
       " ('when', 9257),\n",
       " ('between', 9223),\n",
       " ('field', 9170),\n",
       " ('have', 9126),\n",
       " ('general', 8997),\n",
       " ('theorem', 8993),\n",
       " ('groups', 8874),\n",
       " ('spaces', 8746),\n",
       " ('solutions', 8724),\n",
       " ('type', 8365),\n",
       " ('order', 8309),\n",
       " ('particular', 8258),\n",
       " ('consider', 8216),\n",
       " ('system', 8112),\n",
       " ('let', 8070),\n",
       " ('first', 7994),\n",
       " ('under', 7965),\n",
       " ('there', 7919),\n",
       " ('terms', 7757),\n",
       " ('method', 7729),\n",
       " ('their', 7611),\n",
       " ('certain', 7540),\n",
       " ('random', 7525),\n",
       " ('properties', 7519),\n",
       " ('quantum', 7454),\n",
       " ('conditions', 7434),\n",
       " ('structure', 7331),\n",
       " ('complex', 7272),\n",
       " ('algebras', 7146),\n",
       " ('time', 7133),\n",
       " ('m', 7133),\n",
       " ('linear', 7009)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_math.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which top-100 words are in CS or Math but not both?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_cs = [item[0] for item in c.most_common(100)]\n",
    "top_100_math = [item[0] for item in c_math.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cs_only = set(top_100_cs) - set(top_100_math)\n",
    "cs_only_list = []\n",
    "for word in cs_only:\n",
    "    cs_only_list.append((word, c[word], c_math[word]))\n",
    "cs_only_list_sorted = sorted(cs_only_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm      10358    3213\n",
      "data            8356    3962\n",
      "network         7863     714\n",
      "based           7459    5744\n",
      "information     6939    1512\n",
      "proposed        5701    2212\n",
      "channel         5639     207\n",
      "systems         5609    6862\n",
      "networks        5574     705\n",
      "used            5515    4652\n",
      "algorithms      5510    1206\n",
      "each            5101    5816\n",
      "performance     5002     563\n",
      "approach        4813    5035\n",
      "present         4665    6363\n",
      "been            4601    3779\n",
      "more            4438    5377\n",
      "different       4300    4285\n",
      "analysis        4253    4081\n",
      "problems        4176    4294\n",
      "both            4174    4878\n",
      "graph           4154    5700\n",
      "use             4133    5760\n",
      "only            4042    6933\n",
      "than            3972    4382\n",
      "other           3871    4820\n",
      "optimal         3830    2583\n",
      "complexity      3777     835\n",
      "codes           3615     300\n",
      "into            3564    4722\n",
      "but             3429    4723\n",
      "work            3390    4901\n",
      "rate            3311    2266\n",
      "propose         3295    1706\n",
      "bound           3235    3879\n",
      "scheme          3228    1932\n",
      "nodes           3132     357\n",
      "provide         3127    4175\n"
     ]
    }
   ],
   "source": [
    "for item in cs_only_list_sorted:\n",
    "    print(f'{item[0]:12} {item[1]:7} {item[2]:7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_only = set(top_100_math) - set(top_100_cs)\n",
    "math_only_list = []\n",
    "for word in math_only:\n",
    "    math_only_list.append((word, c[word], c_math[word]))\n",
    "math_only_list_sorted = sorted(math_only_list, key=lambda x: x[2], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prove           2409   18691\n",
      "space           2388   16510\n",
      "group           1102   16219\n",
      "theory          2724   13431\n",
      "finite          2187   12338\n",
      "function        3098   11883\n",
      "give            2087   11460\n",
      "result          2961   11126\n",
      "functions       2267   10933\n",
      "g               1390   10733\n",
      "algebra          473   10530\n",
      "equation         453   10267\n",
      "equations        701    9818\n",
      "class           2355    9681\n",
      "x                971    9461\n",
      "field           1241    9170\n",
      "general         3125    8997\n",
      "theorem         1025    8993\n",
      "groups           607    8874\n",
      "spaces           447    8746\n",
      "solutions       1392    8724\n",
      "type            1216    8365\n",
      "order           3089    8309\n",
      "particular      2467    8258\n",
      "consider        2963    8216\n",
      "let              447    8070\n",
      "under           2980    7965\n",
      "there           3082    7919\n",
      "terms           2131    7757\n",
      "certain         1478    7540\n",
      "random          3083    7525\n",
      "properties      2591    7519\n",
      "quantum         1831    7454\n",
      "conditions      1603    7434\n",
      "structure       2643    7331\n",
      "complex         1569    7272\n",
      "algebras         170    7146\n",
      "m               1181    7133\n"
     ]
    }
   ],
   "source": [
    "for item in math_only_list_sorted:\n",
    "    print(f'{item[0]:12} {item[1]:7} {item[2]:7}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_100_diff(df, set_spec1, set_spec2):\n",
    "    df1 = df[df['set_spec'] == set_spec1]\n",
    "    df2 = df[df['set_spec'] == set_spec2]\n",
    "\n",
    "    desc1 = df1['description'].values\n",
    "    desc2 = df2['description'].values\n",
    "\n",
    "    tokens1 = [tokenize(s) for s in desc1]\n",
    "    tokens2 = [tokenize(s) for s in desc2]\n",
    "\n",
    "    words1 = []\n",
    "    vocab1 = set()\n",
    "\n",
    "    for sent in tokens1:\n",
    "        for word in sent:\n",
    "            words1.append(word)\n",
    "            vocab1.add(word)\n",
    "    wordcount1 = Counter(words1)\n",
    "    \n",
    "    words2 = []\n",
    "    vocab2 = set()\n",
    "\n",
    "    for sent in tokens2:\n",
    "        for word in sent:\n",
    "            words2.append(word)\n",
    "            vocab2.add(word)\n",
    "    wordcount2 = Counter(words2)\n",
    "    \n",
    "    top_100_1 = [item[0] for item in wordcount1.most_common(100)]\n",
    "    top_100_2 = [item[0] for item in wordcount2.most_common(100)]\n",
    "    \n",
    "    only1 = set(top_100_1) - set(top_100_2)\n",
    "    only1_list = []\n",
    "    for word in only1:\n",
    "        only1_list.append((word, wordcount1[word], wordcount2[word]))\n",
    "    only1_list_sorted = sorted(only1_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for item in only1_list_sorted:\n",
    "        print(f'{item[0]:12} {item[1]:7} {item[2]:7}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math vs. CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prove          18691    2409\n",
      "space          16510    2388\n",
      "group          16219    1102\n",
      "theory         13431    2724\n",
      "finite         12338    2187\n",
      "function       11883    3098\n",
      "give           11460    2087\n",
      "result         11126    2961\n",
      "functions      10933    2267\n",
      "g              10733    1390\n",
      "algebra        10530     473\n",
      "equation       10267     453\n",
      "equations       9818     701\n",
      "class           9681    2355\n",
      "x               9461     971\n",
      "field           9170    1241\n",
      "general         8997    3125\n",
      "theorem         8993    1025\n",
      "groups          8874     607\n",
      "spaces          8746     447\n",
      "solutions       8724    1392\n",
      "type            8365    1216\n",
      "order           8309    3089\n",
      "particular      8258    2467\n",
      "consider        8216    2963\n",
      "let             8070     447\n",
      "under           7965    2980\n",
      "there           7919    3082\n",
      "terms           7757    2131\n",
      "certain         7540    1478\n",
      "random          7525    3083\n",
      "properties      7519    2591\n",
      "quantum         7454    1831\n",
      "conditions      7434    1603\n",
      "structure       7331    2643\n",
      "complex         7272    1569\n",
      "algebras        7146     170\n",
      "m               7133    1181\n"
     ]
    }
   ],
   "source": [
    "print_top_100_diff(df, 'math', 'cs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS vs. Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm      10358    3213\n",
      "data            8356    3962\n",
      "network         7863     714\n",
      "based           7459    5744\n",
      "information     6939    1512\n",
      "proposed        5701    2212\n",
      "channel         5639     207\n",
      "systems         5609    6862\n",
      "networks        5574     705\n",
      "used            5515    4652\n",
      "algorithms      5510    1206\n",
      "each            5101    5816\n",
      "performance     5002     563\n",
      "approach        4813    5035\n",
      "present         4665    6363\n",
      "been            4601    3779\n",
      "more            4438    5377\n",
      "different       4300    4285\n",
      "analysis        4253    4081\n",
      "problems        4176    4294\n",
      "both            4174    4878\n",
      "graph           4154    5700\n",
      "use             4133    5760\n",
      "only            4042    6933\n",
      "than            3972    4382\n",
      "other           3871    4820\n",
      "optimal         3830    2583\n",
      "complexity      3777     835\n",
      "codes           3615     300\n",
      "into            3564    4722\n",
      "but             3429    4723\n",
      "work            3390    4901\n",
      "rate            3311    2266\n",
      "propose         3295    1706\n",
      "bound           3235    3879\n",
      "scheme          3228    1932\n",
      "nodes           3132     357\n",
      "provide         3127    4175\n"
     ]
    }
   ],
   "source": [
    "print_top_100_diff(df, 'cs', 'math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# physics:cond-mat vs Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magnetic       19923    1014\n",
      "phase          19644    1879\n",
      "temperature    17235     676\n",
      "spin           16429    1238\n",
      "state          15690    2982\n",
      "energy         14024    3589\n",
      "transition     13548    1229\n",
      "states         12807    3113\n",
      "density        11758    3149\n",
      "systems        10215    6862\n",
      "both            9436    4878\n",
      "different       9185    4285\n",
      "effect          9105     906\n",
      "find            8807    3388\n",
      "critical        8556    2460\n",
      "surface         8429    3978\n",
      "interaction     8389     974\n",
      "lattice         8362    2638\n",
      "found           8182    1732\n",
      "observed        8112     686\n",
      "dynamics        8105    2764\n",
      "electron        8021     221\n",
      "been            7851    3779\n",
      "graphene        7522      60\n",
      "coupling        7508     982\n",
      "present         7487    6363\n",
      "well            7357    4906\n",
      "large           6936    4927\n",
      "low             6922     711\n",
      "potential       6920    2996\n",
      "behavior        6888    2601\n",
      "single          6693    1275\n",
      "current         6690     711\n",
      "experimental    6627     322\n",
      "high            6567    1247\n",
      "due             6562    2121\n",
      "based           6371    5744\n",
      "than            6364    4382\n",
      "k               6350    6816\n",
      "transport       6341     584\n",
      "into            6322    4722\n",
      "electronic      6225      83\n",
      "effects         6170     563\n",
      "scattering      6099    1059\n",
      "superconducting    6058      26\n",
      "strong          6018    2155\n",
      "interactions    6006     628\n",
      "charge          5895     488\n"
     ]
    }
   ],
   "source": [
    "print_top_100_diff(df, 'physics:cond-mat', 'math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math vs. Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prove          18691      65\n",
      "space          16510     198\n",
      "group          16219     101\n",
      "if             15647     145\n",
      "theory         13431     140\n",
      "case           13052     211\n",
      "all            12628     220\n",
      "finite         12338     103\n",
      "give           11460      87\n",
      "result         11126      86\n",
      "functions      10933     182\n",
      "given          10801     227\n",
      "then           10751     220\n",
      "g              10733      16\n",
      "n              10599      63\n",
      "algebra        10530       3\n",
      "equation       10267      23\n",
      "equations       9818      24\n",
      "class           9681     205\n",
      "any             9631     121\n",
      "x               9461      61\n",
      "field           9170      77\n",
      "general         8997     220\n",
      "theorem         8993      31\n",
      "groups          8874      69\n",
      "spaces          8746      36\n",
      "solutions       8724      44\n",
      "type            8365      84\n",
      "order           8309     178\n",
      "particular      8258     197\n",
      "consider        8216     175\n",
      "system          8112     113\n",
      "let             8070      13\n",
      "first           7994     223\n",
      "there           7919     168\n",
      "terms           7757     132\n",
      "certain         7540      67\n",
      "properties      7519     186\n",
      "quantum         7454       6\n",
      "conditions      7434     116\n",
      "structure       7331     213\n",
      "complex         7272     103\n",
      "algebras        7146       0\n",
      "m               7133      34\n"
     ]
    }
   ],
   "source": [
    "print_top_100_diff(df, 'math', 'stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics vs. Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data            1778    3962\n",
      "models           954    5163\n",
      "methods          698    3845\n",
      "analysis         550    4081\n",
      "approach         550    5035\n",
      "based            550    5744\n",
      "algorithm        541    3213\n",
      "distribution     539    4741\n",
      "proposed         490    2212\n",
      "regression       473     794\n",
      "used             464    4652\n",
      "statistical      463    1140\n",
      "estimation       453    1157\n",
      "bayesian         435     326\n",
      "use              384    5760\n",
      "more             378    5377\n",
      "variables        361    2999\n",
      "both             346    4878\n",
      "propose          344    1706\n",
      "information      341    1512\n",
      "process          325    4959\n",
      "selection        317     640\n",
      "statistics       316     955\n",
      "likelihood       315     542\n",
      "than             314    4382\n",
      "performance      304     563\n",
      "parameters       303    2366\n",
      "distributions     301    2019\n",
      "sample           296     926\n",
      "each             296    5816\n",
      "estimator        291    1158\n",
      "different        285    4285\n",
      "other            285    4820\n",
      "inference        282     250\n",
      "many             278    4448\n",
      "simulation       272     593\n",
      "problems         268    4294\n",
      "present          265    6363\n",
      "but              261    4723\n",
      "been             261    3779\n",
      "algorithms       260    1206\n",
      "estimate         258    2002\n",
      "well             252    4906\n",
      "sampling         248     568\n"
     ]
    }
   ],
   "source": [
    "print_top_100_diff(df, 'stat', 'math')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning papers?\n",
    "## First, find subjects that have \"machine learning\" in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_subjects = df[df['subjects'].str.lower().str.contains('machine learning')]['subjects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78         Statistics - Machine Learning,Statistics - App...\n",
       "94         Computer Science - Machine Learning,Statistics...\n",
       "151                            Statistics - Machine Learning\n",
       "224        Computer Science - Social and Information Netw...\n",
       "271        Statistics - Machine Learning,Computer Science...\n",
       "                                 ...                        \n",
       "1601096    Computer Science - Machine Learning,Computer S...\n",
       "1601186    Computer Science - Machine Learning,Statistics...\n",
       "1601240    Computer Science - Cryptography and Security,C...\n",
       "1601258    Computer Science - Computer Vision and Pattern...\n",
       "1601269    Mathematics - Optimization and Control,Compute...\n",
       "Name: subjects, Length: 48564, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_learning_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second, get a count of the subjects that have \"machine learning\" in them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_subject_counts = Counter([item for x in machine_learning_subjects.values for item in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Computer Science - Machine Learning', 41875),\n",
       " ('Statistics - Machine Learning', 31114),\n",
       " ('Computer Science - Computer Vision and Pattern Recognition', 7092),\n",
       " ('Computer Science - Artificial Intelligence', 6945),\n",
       " ('Computer Science - Computation and Language', 3550),\n",
       " ('Computer Science - Neural and Evolutionary Computing', 2963),\n",
       " ('Mathematics - Optimization and Control', 2457),\n",
       " ('Computer Science - Information Theory', 1757),\n",
       " ('Mathematics - Statistics Theory', 1744),\n",
       " ('Computer Science - Information Retrieval', 1662),\n",
       " ('Statistics - Methodology', 1617),\n",
       " ('Computer Science - Cryptography and Security', 1464),\n",
       " ('Computer Science - Robotics', 1323),\n",
       " ('Computer Science - Social and Information Networks', 1198),\n",
       " ('Computer Science - Data Structures and Algorithms', 1179),\n",
       " ('Computer Science - Sound', 1143),\n",
       " ('Statistics - Applications', 1117),\n",
       " ('Statistics - Computation', 962),\n",
       " ('Electrical Engineering and Systems Science - Audio and Speech Processing',\n",
       "  901),\n",
       " ('Electrical Engineering and Systems Science - Signal Processing', 871)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_subject_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
