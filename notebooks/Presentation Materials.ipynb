{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "NOTEBOOKS_DIR = os.path.abspath(os.getcwd())\n",
    "ROOT_DIR = os.path.split(NOTEBOOKS_DIR)[0]\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, 'data', 'processed')\n",
    "\n",
    "FINAL_DF_FILEPATH = os.path.join(PROCESSED_DATA_DIR, 'final.csv')\n",
    "MACHINE_LEARNING_ONLY_FILEPATH = os.path.join(PROCESSED_DATA_DIR, 'machine_learning_only.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(MACHINE_LEARNING_ONLY_FILEPATH, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48564, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Academic researchers often need to face with a large collection of research\n",
      "papers in the literature. This problem may be even worse for postgraduate\n",
      "students who are new to a field and may not know where to start. To address\n",
      "this problem, we have developed an online catalog of research papers where the\n",
      "papers have been automatically categorized by a topic model. The catalog\n",
      "contains 7719 papers from the proceedings of two artificial intelligence\n",
      "conferences from 2000 to 2015. Rather than the commonly used Latent Dirichlet\n",
      "Allocation, we use a recently proposed method called hierarchical latent tree\n",
      "analysis for topic modeling. The resulting topic model contains a hierarchy of\n",
      "topics so that users can browse the topics from the top level to the bottom\n",
      "level. The topic model contains a manageable number of general topics at the\n",
      "top level and allows thousands of fine-grained topics at the bottom level. It\n",
      "also can detect topics that have emerged recently.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_description = df[df['identifier'] == 'oai:arXiv.org:1609.09188']['description'].values[0]\n",
    "print(sample_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_filename = os.path.join(ROOT_DIR, 'models', 'vectorizer_tfidf.pkl')\n",
    "with open(vectorizer_filename, 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "model_filename = os.path.join(ROOT_DIR, 'models', 'nmf_10_model.pkl')\n",
    "with open(model_filename, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tfidf_vector = vectorizer.transform([sample_description])\n",
    "sample_tfidf_vector = sample_tfidf_vector.toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10975632 0.09190316 0.1685538  0.10435482 0.05620574 0.08639332\n",
      " 0.05379542 0.04263916 0.06859368 0.0658737  0.14410896 0.05462832\n",
      " 0.24535656 0.11689494 0.07520069 0.07020213 0.1343602  0.24019797\n",
      " 0.071818   0.06077201 0.08701759 0.08938843 0.08061338 0.0641298\n",
      " 0.07478367 0.05026622 0.09161293 0.06796482 0.09019584 0.07894361\n",
      " 0.09123438 0.04048717 0.11634296 0.21804503 0.06300366 0.12508145\n",
      " 0.03376272 0.0891519  0.05716179 0.06000553 0.03719288 0.04164689\n",
      " 0.05881559 0.375308   0.15463678 0.06822834 0.12644252 0.03500645\n",
      " 0.10722751 0.11067416 0.07596778 0.06104489 0.08540671 0.10238222\n",
      " 0.08680664 0.29989887 0.43815856 0.07023727 0.04040139 0.03736698\n",
      " 0.06578595 0.09360687]\n"
     ]
    }
   ],
   "source": [
    "print(sample_tfidf_vector[sample_tfidf_vector > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tfidf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0., 0., 0., ..., 0.11, 0.09, 0.17, ..., 0., 0., 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"[0., 0., 0., ..., 0.11, 0.09, 0.17, ..., 0., 0., 0.]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.004, 0.   , 0.   , 0.001, 0.029, 0.   , 0.   , 0.015, 0.003,\n",
       "       0.002])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_nmf_topic_loadings = model.transform(sample_tfidf_vector.reshape(1, -1))[0]\n",
    "sample_nmf_topic_loadings.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004, 0.   , 0.   , 0.001, 0.029, 0.   , 0.   , 0.015, 0.003, 0.002]\n"
     ]
    }
   ],
   "source": [
    "print(\"[0.004, 0.   , 0.   , 0.001, 0.029, 0.   , 0.   , 0.015, 0.003, 0.002]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
